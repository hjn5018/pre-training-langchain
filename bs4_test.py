import os
import bs4
import streamlit as st
from dotenv import load_dotenv

from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
os.environ["USER_AGENT"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Streamlit ì„¤ì •
st.set_page_config(page_title="LangChain ë¸”ë¡œê·¸ QA", layout="wide")
st.title("ğŸ“˜ LangChain ë¸”ë¡œê·¸ ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì„œë¹„ìŠ¤")
st.caption("Replit ë° LangGraph ê´€ë ¨ ë¸”ë¡œê·¸ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€í•©ë‹ˆë‹¤.")

# ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬ ìºì‹±
@st.cache_resource
def load_vectorstore():
    urls = [
        "https://blog.langchain.dev/customers-replit/",
        "https://blog.langchain.dev/langgraph-v0-2/"
    ]

    loader = WebBaseLoader(
        web_paths=urls,
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(class_=("article-header", "article-content"))
        ),
        requests_kwargs={
            "headers": {
                "User-Agent": os.environ["USER_AGENT"]
            }
        }
    )
    docs = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectorstore = FAISS.from_documents(split_docs, embeddings)

    return vectorstore

# ë²¡í„°ìŠ¤í† ì–´ ë° QA ì²´ì¸ êµ¬ì„±
vectorstore = load_vectorstore()
llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model="gpt-3.5-turbo")
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), return_source_documents=True)

# ì‚¬ìš©ì ì…ë ¥
query = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: Replitì€ LangChainì„ ì–´ë–»ê²Œ ì‚¬ìš©í–ˆë‚˜ìš”?", key="user_query")

if query:
    with st.spinner("ğŸ” ë‹µë³€ ìƒì„± ì¤‘..."):
        result = qa_chain.invoke({"query": query})
        st.markdown("### ğŸ’¡ ë‹µë³€")
        st.write(result["result"])

        st.markdown("---")
        st.markdown("### ğŸ“„ ì°¸ì¡° ë¬¸ì„œ")
        for doc in result["source_documents"]:
            source = doc.metadata.get("source", "")
            st.markdown(f"- [{source}]({source})")

